{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf96HPEO3CAQ",
        "outputId": "2a1db06d-c99f-48b4-a58b-3f23a8e20c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Likes): 61274.52631578947\n",
            "Mean Absolute Error (Likes): 138.21052631578948\n",
            "Mean Absolute Error (Time Since Posted): 11.947368421052632\n",
            "Root Mean Squared Error (Time Since Posted): 17.635192088548397\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"instagram_reach.csv\", index_col=[0])\n",
        "label = LabelEncoder()\n",
        "caption_vectorizer = CountVectorizer()\n",
        "hasht_vectorizer = CountVectorizer()\n",
        "pca = PCA(n_components=50)\n",
        "likes_model = LinearRegression()\n",
        "time_model = LinearRegression()\n",
        "\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the data into input features (X) and target variables (y)\n",
        "X = data.drop(['Likes', 'Time since posted'], axis=1)  # Remove the target variables from the input features\n",
        "y_likes = data['Likes']  # Target variable: number of likes\n",
        "y_time_since_posted = data['Time since posted'].str.split().str[0].astype(int)  # Target variable: time since posted\n",
        "\n",
        "X = X.reset_index( drop = True)\n",
        "\n",
        "X_caption = caption_vectorizer.fit_transform(X['Caption'])\n",
        "X_caption = pd.DataFrame(X_caption.toarray(), columns=caption_vectorizer.get_feature_names_out())\n",
        "X.drop('Caption', axis=1, inplace=True)\n",
        "\n",
        "X = pd.concat([X, X_caption], axis=1, join = 'inner')\n",
        "\n",
        "\n",
        "X_hash = hasht_vectorizer.fit_transform(X['Hashtags'])\n",
        "X_hash = pd.DataFrame(X_hash.toarray(), columns=hasht_vectorizer.get_feature_names_out())\n",
        "X.drop('Hashtags', axis=1, inplace=True)\n",
        "\n",
        "X = pd.concat([X, X_hash], axis = 1, join = 'inner')\n",
        "\n",
        "X['username'] = label.fit_transform(X['USERNAME'])\n",
        "\n",
        "X =X.drop(['USERNAME'], axis = 1)\n",
        "\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_likes_train, y_likes_test, y_time_train, y_time_test = train_test_split(\n",
        "    X_pca, y_likes, y_time_since_posted, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "likes_model.fit(X_train, y_likes_train)\n",
        "\n",
        "likes_predictions = likes_model.predict(X_test)\n",
        "likes_predictions = likes_predictions.round().astype(int)\n",
        "\n",
        "mse_likes = mean_squared_error(y_likes_test, likes_predictions)\n",
        "mae_likes = mean_absolute_error(y_likes_test, likes_predictions)\n",
        "print(\"Mean Squared Error (Likes):\", mse_likes)\n",
        "print(\"Mean Absolute Error (Likes):\", mae_likes)\n",
        "\n",
        "time_model.fit(X_train, y_time_train)\n",
        "\n",
        "time_predictions = time_model.predict(X_test)\n",
        "time_predictions = time_predictions.round().astype(int)\n",
        "time_pred = np.array([str(int(pred)) + ' hours' for pred in time_predictions])\n",
        "\n",
        "mae_time = mean_absolute_error(y_time_test, time_predictions)\n",
        "rmse_time = mean_squared_error(y_time_test, time_predictions, squared=False)\n",
        "print(\"Mean Absolute Error (Time Since Posted):\", mae_time)\n",
        "print(\"Root Mean Squared Error (Time Since Posted):\", rmse_time)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_k7GV1f3esl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}